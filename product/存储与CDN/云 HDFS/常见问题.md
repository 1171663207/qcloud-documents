## 一般性问题

### 如何购买 CHDFS?
若您需使用 CHDFS，可参见 CHDFS [购买指南](https://cloud.tencent.com/document/product/1105/36359) 文档了解相关费用说明，可参见 [快速入门](https://cloud.tencent.com/document/product/1105/36364) 文档完成服务的开通和使用。


### 可以跨地域访问 CHDFS 吗？
不能，目前只支持在 VPC 网络内，通过同地域访问 CHDFS。

### 使用 CHDFS 有 hadoop 环境要求吗？
所有 Hadoop 2.x 以上版本都可以使用。

### CHDFS 支持并发读写同一个文件吗？
CHDFS 支持并发读同一个文件，但是同一个时刻，只支持一个客户端写同一个文件。


## Ranger 鉴权和认证常见问题

### Hive 指定 COSN 或 OFS 路径建表时，报错“HiveAccessControlException”？

您需要在 hive 中放开对 URL 的校验，需要在 ranger 控制台 hive 里配置允许 url 权限。

![Ranger Admin](https://qcloudimg.tencent-cloud.cn/raw/8db0474e6ec152f92b61c98f6ac5d83c.png)

>!请您注意查看报错日志的格式，这种报错多半是 Ranger 服务报出来的，大多数情况下是 ranger admin 配置权限有误。


### kerberos 下 spark 提交任务时，报错“HiveAccessControlException”？

应用程序需要与其他安全 Hadoop 文件系统交互，则需要在启动时将其 URI 显式提供给 Spark，配置参数 `spark.kerberos.access.hadoopFileSystems=cosn://bucket-appid,ofs://f4mxxxxxxxx-Xxxx.chdfs.ap-guangzhou.myqcloud.com`，详情可参考 [Spark 官方文档](https://spark.apache.org/docs/latest/security.html)。

### SPARK 删表不进回收站？

spark 中 create table 指定 Location 等价于创建外部表，删除外部表无法删除数据，具体可参考 [Spark 官方文档](https://spark.apache.org/docs/latest/sql-migration-guide.html#upgrading-from-spark-sql-16-to-20)。另外 hive on mr 情况下 drop table 可删除。

### Hive 执行 INSERT 语句时，报错“AccessControlException”？

hive 默认引擎是 MapReduce，yarn-site.xml 文件新增配置项。

```
<property>
    <name>mapreduce.job.hdfs-servers</name>
    <value>
        ofs://f4mxxxxxxx-XXXX,cosn://bucketname-appid,${fs.defaultFS}
    </value>
</property>
```

- 如果 hive 引擎是 tez，则在 tez-site.xml 文件中新增配置项 tez.job.fs-servers，value 值同上。
- 如果是 beeline 连 hive，需要重启 hiveserver2 加载新的 yarn-site 配置。

### 访问 OFS 报错，该如何处理？

报错是 ofs 后端返回的，启用 ranger 后，需要关闭 posix。

- 如果是 CHDFS，则操作如下：
![chdfs关闭posix](https://qcloudimg.tencent-cloud.cn/raw/c3949ae42d0e7dcab055960f516b9ea6.png)
- 如果是融合 bucket，则操作如下：
![](https://qcloudimg.tencent-cloud.cn/raw/1d1d4489dbf34ac01197d668fdbf2d22.png)

### YARN 命令行提交任务，报错“renew token failed”？

yarn 命令行执行时，需要 -Dmapreduce.job.send-token-conf 参数。

### 如何自建 cosranger？

请参考 [COS Ranger 权限体系解决方案](https://cloud.tencent.com/document/product/436/51125)、[CHDFS Ranger 权限体系解决方案](https://cloud.tencent.com/document/product/1105/53307) 文档。

### 腾讯云 EMR 中如何启用 Ranger？

在 emr 控制台购买 Ranger 和 cosranger 组件，省去自己部署的步骤。

* 如果是 CHDFS，在 core-site.xml 中新增配置项：fs.ofs.ranger.enable.flag，设置为：true；
* 如果是 COSN，在 core-site.xml 中新增配置项：fs.cosn.credentials.provider，设置为：org.apache.hadoop.fs.auth.RangerCredentialsProvider。

### 启用 cosranger 后，执行 hadoop fs 命令时，报错“ java.lang.IllegalArgumentException: Failed to specify server's Kerberos principal name”？

* 在 core-site.xml 中新增配置项：qcloud.object.storage.kerberos.principal  
* 如果是 HDFS 集群报该错误，在 core-site.xml 中新增配置项：dfs.namenode.kerberos.principal

### 修改 Ranger policy 未生效？

* 如果是 CHDFS，修改 cosranger 配置文件 ranger-chdfs-security.xml 中的配置项：ranger.plugin.chdfs.policy.pollIntervalMs，将值调小（单位毫秒）；
* 如果是 COSN，修改 cosranger 配置文件 ranger-cos-security.xml 中的配置项：ranger.plugin.cos.policy.pollIntervalMs，将值调小（单位毫秒）。

### alluxio 包污染，该如何处理？

在 /usr/local/service 下执行以下命令：
```
find . -name "*.jar" -exec grep -Hls "org/apache/hadoop/fs/cosn/ranger/client/RangerQcloudObjectStorageClientImpl" {} \;
```

这种问题出在大数据 EMR 团队在升级 hadoop ranger client 的 jar 包时，有部分组件未完全升级导致的包污染，使用上面的命令行找到相关  jar 包删掉即可。





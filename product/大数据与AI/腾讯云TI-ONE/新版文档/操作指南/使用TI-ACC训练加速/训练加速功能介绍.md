


训练加速中的通信加速能力通过兼容原生的 DDP、PS 工具提供，用户无需修改原生的使用代码可直接进行使用，数据 IO 优化、自适应 FP16 都通过封装好的简单函数/类进行提供，用户仅需增加几行代码便可使用。

## 使用 DDP 分布式训练通信优化（PyTorch+DPP）

以兼容原生 DDP 的方式启动训练脚本，无需进行训练代码的修改，启动命令参考示例如下：
```
python3 -u -m tiacc_training.torch.distributed.launch --nproc_per_node $GPUS_PER_NODE --nnodes $NNODES --node_rank $NODE_RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT main.py
```
DDP 分布式训练通信优化实测效果：
（加速效果在多机多卡场景方有体现，单机多卡场景与原生 DDP 性能无异。）

<table>
<thead>
<tr>
<th>硬件环境</th>
<th>模型</th>
<th>GPU 卡数</th>
<th>原生DDP(examples/sec per V100)</th>
<th>TI-ACC通信优化(examples/sec per V100)</th>
</tr>
</thead>
<tbody><tr>
<td rowspan="3">腾讯云GN10Xp.20XLARGE320</td>
<td rowspan="3">resnext50_32x4d</td>
<td>1（单机）</td>
<td>227</td>
<td>227</td>
</tr>
<tr>  
<td>8（单机）</td>
<td>215</td>
<td>215</td>
</tr>
<tr>  
<td>16（双机）</td>
<td>116</td>
<td>158.6</td>
</tr>
</tbody></table>

## 使用数据 IO 优化
```
#数据预处理，IO 优化
import tiacc_training.torch
train_dataset = tiacc_training.torch.tiacc_torch_warp.IndexTFRDataset(tfrecored_dir, tfrecord_file, transform)
```
数据 IO 优化实测效果：

<table>
<thead>
<tr>
<th>硬件环境</th>
<th>模型</th>
<th>GPU 卡数</th>
<th>原生PyTorch(examples/sec per V100)</th>
<th>TI-ACC 数据 IO 优化(examples/sec per V100)</th>
</tr>
</thead>
<tbody><tr>
<td rowspan="2">腾讯云GN10Xp.20XLARGE320</td>
<td>resnet50            mmcls</td>
<td>8（单机）</td>
<td>70.8</td>
<td>350.5</td>
</tr>
<tr> 
<td>centernet              mmdet</td>
<td>8（单机）</td>
<td>26.4</td>
<td>28.6</td>
</tr>
</tbody></table>

tfrecord_file 可使用 TI-ACC 提供的 tools 工具进行生成：

|工具名称	|具体功能|	输入参数|	使用示例|
|-|-|-|-|
|tiacc_training/tools/general_image_list.py 	|生成 tfrecord_file 需要的 image list|● 	img_dir（必填）:图片存放路径，下面若干个文件夹，文件夹名为当前类别名<br>●	img_list（必填）:希望生成的list文件名，格式为 图片路径 当前图片类别标签，list文件示例<br>●	label_str2int（非必填）:类别名（str）到类别id（int）的映射关系文件，若不输入，则会自动生成；label_str2int文件示例|python3 tiacc_training/tools/general_image_list.py --img_dir val_demo/ --img_list val_list|
|tiacc_training/tools/img2tfrecord.py|	转tfrecord格式，生成数据IO优化需要的tfrecord_file|	●	img_dir:图片存放路径<br>●	img_list: 1中生成<br>●	tfrecords_name: 生成数据名称<br>●	dataset_type: 目前支持ImageFold、coco两种<br>●	workers（非必填）: 默认为0，tfrecord生成支持多线程，若需加速，可指定大于1的整数|	python3 tiacc_training/tools/img2tfrecord.py --img_dir val_demo --img_list val_list --tfrecords_name val_demo --dataset_type ImageFold|

## 使用自适应混合精度优化（PyTorch）
```
import torch.cuda.amp as amp 
import tiacc_training.torch
scaler = amp.GradScaler() 
#实例化自适应混合精度策略类的对象
policy = tiacc_training.torch .tiacc_torch_warp.MixedPrecision_TrainingPolicy(policy,start_step,hold_step,end_step,interval_time,interval_hold_time)
#根据输入的参数得到当前epoch是否需要开启混合精度
mixed_precision = policy.enable_mixed_precision(epoch,lr=lr,loss=loss,scaler=scaler)
with amp.autocast(enabled=mixed_precision):
     outputs = model(inputs)
     loss = criterion(outputs, targets)
scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()
```

自适应混合精度优化实测效果：

<table>
<thead>
<tr>
<th>硬件环境</th>
<th>模型</th>
<th>GPU 卡数</th>
<th>原生PyTorch(examples/sec per V100)</th>
<th>TI-ACC 数据 IO 优化(examples/sec per V100)</th>
<th>TI-ACC 数据 IO+自适应混合精度优化(examples/sec per V100)</th>
</tr>
</thead>
<tbody><tr>
<td rowspan="2">腾讯云GN10Xp.20XLARGE320</td>
<td>resnet50  mmcls</td>
<td>8（单机）</td>
<td>70.8</td>
<td>350.5</td>
<td>379.2</td>
</tr>
<tr> 
<td>centernet              mmdet</td>
<td>8（单机）</td>
<td>26.4</td>
<td>28.6</td>
<td>30.6</td>
</tr>
</tbody></table>

## 使用优化后的 embedding 变量构造（TensorFlow+PS）

```
# 启动容器
docker run -itd --name tiacc-rec-fm --network=host --ipc=host ccr.ccs.tencentyun.com/ti-platform/tensorflow:1.15.5-py3-rec-0121
# 进入容器
docker exec -it tiacc-rec-fm bash
# 原生tensorflow embedding使用方法
cd wideanddeep && bash start_all.sh --fm
# tiacc lookup优化使用方法
cd wideanddeep && bash start_all.sh --tiacc --fm
```

embedding 变量构造+lookup 计算优化实测效果：

<table>
<thead>
<tr>
<th>硬件环境</th>
<th>模型</th>
<th>GPU 卡数</th>
<th>原生 TensorFlow(global_steps/sec per V100)</th>
<th>TI-ACC 优化后(global_steps/sec per V100)</th>
</tr>
</thead>
<tbody><tr>
<td rowspan="2">腾讯云GN10Xp.20XLARGE320</td>
<td>DeepFM</td>
<td>16（双机）</td>
<td>41.9 - 56</td>
<td>96.1 - 103.3</td>
</tr>
<tr> 
<td>Wide &amp; Deep</td>
<td>16（双机）</td>
<td>49.9 - 69</td>
<td>120 - 128</td>
</tr>
</tbody></table>
